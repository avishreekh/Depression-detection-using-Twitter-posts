{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Depression_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OGe5gLWZ4uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n93McsYQq-q",
        "colab_type": "text"
      },
      "source": [
        "# Data Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLFHOwyHFuT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNgo8E28HPSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/avishreekh/Depression-prediction/master/data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print(len(df))\n",
        "train_raw_df, test_raw_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['label'])\n",
        "train_raw_df = train_raw_df.reset_index(drop=True)\n",
        "test_raw_df = test_raw_df.reset_index(drop=True)\n",
        "print(len(train_raw_df))\n",
        "print(len(test_raw_df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6x_fyzOWgkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_raw_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0qX4V91YxPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_raw_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZPcVW09ZWR5",
        "colab_type": "text"
      },
      "source": [
        "#Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhJBhw8sZElB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_pattern(ip, pattern):\n",
        "  reg_ex = re.findall(pattern, str(ip))\n",
        "  for exp in reg_ex:\n",
        "    ip = re.sub(exp, '', str(ip))\n",
        "  return str(ip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao155rCgazFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(df):\n",
        "  df['text'] = np.vectorize(remove_pattern)(df['text'], '@[\\w]*')\n",
        "  df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")\n",
        "  df['text'] = df['text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdZrR2hdcR_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_data(train_raw_df)\n",
        "clean_data(test_raw_df)\n",
        "train_raw_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQqBEtmOJ02y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.DataFrame({'id': range(len(train_raw_df)),\n",
        "                         'label': train_raw_df['label'],\n",
        "                         'alpha': ['a']*train_raw_df.shape[0],\n",
        "                         'text': train_raw_df['text'].replace(r'\\n', ' ', regex=True)})\n",
        "test_df = pd.DataFrame({'id': range(len(test_raw_df)),\n",
        "                         'label': test_raw_df['label'],\n",
        "                         'alpha': ['a']*test_raw_df.shape[0],\n",
        "                         'text': test_raw_df['text'].replace(r'\\n', ' ', regex=True)})\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-ZZ3402PUH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.to_csv('/content/data/train.tsv', sep='\\t', index=False, header=False)\n",
        "test_df.to_csv('/content/data/dev.tsv', sep='\\t', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZAfXH3jQ8nV",
        "colab_type": "text"
      },
      "source": [
        "#Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSsqOBfXZUg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pickle\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "from tqdm import tqdm_notebook, trange\n",
        "import os\n",
        "import csv \n",
        "import sys\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
        "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
        "\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYQpHy5sQlGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    def __init__(self, guid, text, label=None):\n",
        "        self.guid = guid\n",
        "        self.text = text\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "class DataProcessor(object):\n",
        "    def get_train_examples(self, data_dir):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            for line in reader:\n",
        "                if sys.version_info[0] == 2:\n",
        "                    line = list(unicode(cell, 'utf-8') for cell in line)\n",
        "                lines.append(line)\n",
        "            return lines\n",
        "\n",
        "\n",
        "class BinaryClassificationProcessor(DataProcessor):\n",
        "    def get_train_examples(self, data_dir):\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"0\", \"1\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            text = line[3]\n",
        "            label = line[1]\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text=text, label=label))\n",
        "        return examples\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMA9YRHnWOxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputFeatures(object):\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens, max_length):\n",
        "    while True:\n",
        "        if len(tokens) <= max_length:\n",
        "            break\n",
        "        else:\n",
        "            tokens.pop()\n",
        "\n",
        "\n",
        "def convert_example_to_feature(example_row):\n",
        "    example, label_map, max_seq_length, tokenizer = example_row\n",
        "\n",
        "    tokens = tokenizer.tokenize(example.text)        \n",
        "    \n",
        "    if len(tokens) > max_seq_length - 2:\n",
        "            tokens = tokens[:(max_seq_length - 2)]\n",
        "\n",
        "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "    segment_ids = [0] * len(tokens)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    padding = [0] * (max_seq_length - len(input_ids))\n",
        "    input_ids += padding\n",
        "    input_mask += padding\n",
        "    segment_ids += padding\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    label_id = label_map[example.label]\n",
        "    \n",
        "    return InputFeatures(input_ids=input_ids,\n",
        "                         input_mask=input_mask,\n",
        "                         segment_ids=segment_ids,\n",
        "                         label_id=label_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHCyW1oOZ1TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processor = BinaryClassificationProcessor()\n",
        "train_examples = processor.get_train_examples('.')\n",
        "train_examples_len = len(train_examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xNKSlY7biqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEFUmQYMfDTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aghWaCGLbpOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khfvEos3e_EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map = {label: i for i, label in enumerate(label_list)}\n",
        "train_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer) for example in train_examples]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSbQCfUteSyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "process_count = cpu_count() - 1\n",
        "if __name__ ==  '__main__':\n",
        "    print(f'Preparing to convert {train_examples_len} examples..')\n",
        "    print(f'Spawning {process_count} processes..')\n",
        "    with Pool(process_count) as p:\n",
        "        train_features = list(tqdm_notebook(p.imap(convert_example_to_feature, train_examples_for_processing), total=train_examples_len))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbvl_OeZf0fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"train_features.pkl\", \"wb\") as f:\n",
        "    pickle.dump(train_features, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CjhjKyl2_2Z",
        "colab_type": "text"
      },
      "source": [
        "# Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnyBhYq-k6XA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", cache_dir=\"/content/cache\", num_labels=num_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpbaJMf43ZhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syG-YwGc3ilX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U9LzlF-34VF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BATCH_SIZE = 256\n",
        "EVAL_BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 1\n",
        "RANDOM_SEED = 42\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "WARMUP_PROPORTION = 0.1\n",
        "\n",
        "num_train_optimization_steps = int(train_examples_len / TRAIN_BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS) * NUM_TRAIN_EPOCHS\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=LEARNING_RATE,\n",
        "                     warmup=WARMUP_PROPORTION,\n",
        "                     t_total=num_train_optimization_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp4Lmvk_4_0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_step = 0\n",
        "nb_tr_steps = 0\n",
        "tr_loss = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PktlJeO05A2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
        "all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQqRAnL7dt0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfIhCNEVeKsQ",
        "colab_type": "text"
      },
      "source": [
        "#Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nsUzIKzeJvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train()\n",
        "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(tqdm_notebook(train_dataloader, desc=\"Iteration\")):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, segment_ids, label_ids = batch\n",
        "\n",
        "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
        "        \n",
        "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
        "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "        loss.backward()\n",
        "        print(\"\\r Loss: %f\" % loss, end='')\n",
        "        \n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSwf7BLQeorg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "\n",
        "CONFIG_NAME = \"config.json\"\n",
        "WEIGHTS_NAME = \"pytorch_model.bin\"\n",
        "\n",
        "output_model_file = os.path.join('./output', WEIGHTS_NAME)\n",
        "output_config_file = os.path.join('./output', CONFIG_NAME)\n",
        "\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary('./output')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}